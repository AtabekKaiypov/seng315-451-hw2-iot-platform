# ğŸ“ Hocaya Sunum KÄ±lavuzu

## IoT Platform - Kafka Messaging Layer Entegrasyonu

---

## ğŸ“‹ Proje Ã–zeti

**Ã–ÄŸrenci:** Messaging Layer Ekibi  
**Tarih:** AralÄ±k 2025  
**Konu:** SENG315-451 HW2 - IoT Sensor Data Collection Platform

### Tamamlanan Katmanlar

- âœ… **API Layer (FastAPI)** - REST endpoints
- âœ… **Messaging Layer (Kafka)** - Producer & Consumer
- âœ… **Data Layer (SQLAlchemy)** - Database CRUD

---

## ğŸ¯ GÃ¶sterim Senaryosu

### AdÄ±m 1: Kafka'yÄ± BaÅŸlat (1 dakika)

```bash
# Terminal'de
cd C:\Users\hp\VsProjects\seng315-451-hw2-iot-platform
docker-compose up -d

# Kafka'nÄ±n baÅŸladÄ±ÄŸÄ±nÄ± gÃ¶ster
docker ps
docker logs kafka --tail 20
```

**AÃ§Ä±klama:** "Kafka ve Zookeeper Docker container'larÄ± baÅŸlatÄ±ldÄ±. Kafka localhost:9092'de Ã§alÄ±ÅŸÄ±yor."

---

### AdÄ±m 2: API'yi BaÅŸlat (30 saniye)

```bash
# Yeni terminal penceresi
uvicorn app.main:app --reload --port 8000
```

**Terminal Ã§Ä±ktÄ±sÄ±:**
```
INFO:     Kafka Producer baÅŸarÄ±yla baÅŸlatÄ±ldÄ±
INFO:     Application startup complete.
INFO:     Uvicorn running on http://127.0.0.1:8000
```

**AÃ§Ä±klama:** "FastAPI baÅŸlatÄ±ldÄ± ve startup event'inde Kafka Producer otomatik baÅŸladÄ±."

---

### AdÄ±m 3: Consumer Servisini BaÅŸlat (30 saniye)

```bash
# Yeni terminal penceresi
python -m app.messaging.consumer_service
```

**Terminal Ã§Ä±ktÄ±sÄ±:**
```
INFO - === Kafka Consumer Servisi BaÅŸlatÄ±lÄ±yor ===
INFO - Kafka Consumer baÅŸlatÄ±ldÄ±: sensor.readings
INFO - Mesajlar bekleniyor...
```

**AÃ§Ä±klama:** "Consumer servisi Kafka topic'inden mesaj okumaya baÅŸladÄ±."

---

### AdÄ±m 4: Swagger UI'dan Test (3 dakika)

#### 4.1. Swagger'Ä± AÃ§

TarayÄ±cÄ±da: http://localhost:8000/docs

**AÃ§Ä±klama:** "FastAPI otomatik olarak interaktif API dokÃ¼mantasyonu oluÅŸturdu."

---

#### 4.2. Ä°lk Veriyi GÃ¶nder

**Endpoint:** POST `/sensor/readings`

**Body:**
```json
{
  "sensor_id": "temp_sensor_01",
  "sensor_type": "temperature",
  "value": 23.5
}
```

**"Execute" butonuna tÄ±kla**

**Response (200 OK):**
```json
{
  "id": 1,
  "sensor_id": "temp_sensor_01",
  "sensor_type": "temperature",
  "value": 23.5,
  "timestamp": "2025-12-01T22:15:30.123456"
}
```

**Consumer terminal'ini gÃ¶ster:**
```
INFO - Mesaj alÄ±ndÄ±: partition=0, offset=0
INFO - Veri DB'ye kaydedildi: temp_sensor_01 (temperature) = 23.5
```

**AÃ§Ä±klama:** 
1. "API veriyi aldÄ±"
2. "Kafka Producer veriyi sensor.readings topic'ine gÃ¶nderdi"
3. "Consumer Kafka'dan mesajÄ± okudu"
4. "SQLAlchemy ile veritabanÄ±na kaydetti"

---

#### 4.3. Daha Fazla Veri GÃ¶nder

Swagger'dan 3-4 veri daha gÃ¶nder:

```json
{"sensor_id": "temp_sensor_01", "sensor_type": "temperature", "value": 24.0}
{"sensor_id": "temp_sensor_02", "sensor_type": "temperature", "value": 22.8}
{"sensor_id": "humidity_sensor_01", "sensor_type": "humidity", "value": 65.0}
{"sensor_id": "humidity_sensor_01", "sensor_type": "humidity", "value": 67.5}
```

Her seferinde Consumer terminal'de log gÃ¶ster.

---

#### 4.4. En Son Veriyi Oku

**Endpoint:** GET `/sensor/readings/latest/temp_sensor_01`

**Response:**
```json
{
  "id": 2,
  "sensor_id": "temp_sensor_01",
  "sensor_type": "temperature",
  "value": 24.0,
  "timestamp": "2025-12-01T22:16:45.654321"
}
```

**AÃ§Ä±klama:** "En son kaydedilen veri veritabanÄ±ndan okundu."

---

#### 4.5. GeÃ§miÅŸ Verileri Oku

**Endpoint:** GET `/sensor/readings/temp_sensor_01?limit=10`

**Response:** Liste olarak tÃ¼m veriler

**AÃ§Ä±klama:** "SensÃ¶r geÃ§miÅŸi timestamp'e gÃ¶re sÄ±ralanmÄ±ÅŸ ÅŸekilde dÃ¶ndÃ¼."

---

#### 4.6. Ortalama Hesapla (Analytics)

**Endpoint:** GET `/analytics/average?sensor_type=temperature`

**Response:**
```json
{
  "sensor_type": "temperature",
  "average": 23.433333333333334
}
```

**AÃ§Ä±klama:** "SQLAlchemy aggregate fonksiyonu ile tÃ¼m temperature sensÃ¶rlerinin ortalamasÄ± hesaplandÄ±."

---

### AdÄ±m 5: Kafka Topic'ini DoÄŸrudan GÃ¶ster (1 dakika)

```bash
# Terminal'de
docker exec -it kafka kafka-topics --bootstrap-server localhost:9092 --list
```

**Ã‡Ä±ktÄ±:**
```
sensor.readings
```

**MesajlarÄ± oku:**
```bash
docker exec -it kafka kafka-console-consumer --bootstrap-server localhost:9092 --topic sensor.readings --from-beginning
```

**Ã‡Ä±ktÄ±:**
```json
{"sensor_id":"temp_sensor_01","sensor_type":"temperature","value":23.5,"timestamp":"2025-12-01T22:15:30.123456"}
{"sensor_id":"temp_sensor_01","sensor_type":"temperature","value":24.0,"timestamp":"2025-12-01T22:16:45.654321"}
...
```

**AÃ§Ä±klama:** "TÃ¼m mesajlar Kafka topic'inde saklanÄ±yor. Consumer bu mesajlarÄ± okuyup DB'ye yazÄ±yor."

---

### AdÄ±m 6: VeritabanÄ±nÄ± GÃ¶ster (30 saniye)

```bash
# SQLite DB'yi kontrol et
sqlite3 sensor_db.sqlite3
```

**SQL sorgula:**
```sql
SELECT * FROM sensor_readings ORDER BY timestamp DESC LIMIT 5;
```

**AÃ§Ä±klama:** "Veriler SQLite veritabanÄ±nda kalÄ±cÄ± olarak saklanÄ±yor."

---

### AdÄ±m 7: Test Script'ini Ã‡alÄ±ÅŸtÄ±r (1 dakika)

```bash
python test_kafka.py
```

**Ã‡Ä±ktÄ±:**
```
==================================================
IoT Platform - Kafka Entegrasyon Testi
==================================================
[TEST 1] POST /sensor/readings - Veri gÃ¶nderme
--------------------------------------------------
âœ… POST baÅŸarÄ±lÄ±!

[TEST 2] GET /sensor/readings/latest/temp_sensor_01
--------------------------------------------------
âœ… GET latest baÅŸarÄ±lÄ±!

[TEST 3] GET /sensor/readings/temp_sensor_01?limit=10
--------------------------------------------------
âœ… GET history baÅŸarÄ±lÄ±!

[TEST 4] GET /analytics/average?sensor_type=temperature
--------------------------------------------------
âœ… GET analytics baÅŸarÄ±lÄ±!

[TEST 5] Ã‡oklu veri gÃ¶nderme
--------------------------------------------------
âœ… Ã‡oklu veri gÃ¶nderme baÅŸarÄ±lÄ±!

ğŸ‰ TÃœM TESTLER BAÅARILI!
```

**AÃ§Ä±klama:** "Otomatik test script'i tÃ¼m endpoint'leri ve Kafka entegrasyonunu doÄŸruladÄ±."

---

## ğŸ“Š Mimari Diyagram (Tahtaya Ã‡iz)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   SensÃ¶r    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ HTTP POST
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FastAPI (port 8000)      â”‚
â”‚  POST /sensor/readings    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â–º Kafka Producer â”€â”€â–º [sensor.readings topic]
       â”‚                              â”‚
       â””â”€â”€â–º DB (geÃ§ici, ID iÃ§in)      â”‚
                                      â–¼
                              Kafka Consumer
                              (ayrÄ± process)
                                      â”‚
                                      â–¼
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚  SQLite Database â”‚
                            â”‚  sensor_readings â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
                              CRUD Operations
                                      â”‚
                                      â–¼
                        GET /sensor/readings/latest/{id}
                        GET /sensor/readings/{id}
                        GET /analytics/average
```

---

## ğŸ› ï¸ Teknik Detaylar

### KullanÄ±lan Teknolojiler

| Katman | Teknoloji | Versiyon |
|--------|-----------|----------|
| API | FastAPI | 0.104.1 |
| Web Server | Uvicorn | 0.24.0 |
| Messaging | Apache Kafka | 7.5.0 (Confluent) |
| Kafka Client | aiokafka | 0.10.0 |
| Database | SQLite | - |
| ORM | SQLAlchemy | 2.0.23 |
| Validation | Pydantic | 2.5.0 |
| Container | Docker Compose | - |

### Dosya YapÄ±sÄ±

```
app/
â”œâ”€â”€ main.py                    # FastAPI, endpoints, startup/shutdown
â”œâ”€â”€ schemas.py                 # Pydantic models (validation)
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ db.py                  # SQLAlchemy engine, session
â”‚   â”œâ”€â”€ models.py              # SensorReading model
â”‚   â””â”€â”€ crud.py                # Database operations
â””â”€â”€ messaging/                 # â­ KAFKA LAYER
    â”œâ”€â”€ config.py              # Kafka config
    â”œâ”€â”€ producer.py            # Async producer
    â””â”€â”€ consumer_service.py    # Async consumer (ayrÄ± process)
```

### Kafka Configuration

**Topic:** `sensor.readings`  
**Partitions:** 1 (default)  
**Replication Factor:** 1  
**Consumer Group:** `sensor-consumer-group`  
**Serialization:** JSON

### Database Schema

**Table:** `sensor_readings`

| Column | Type | Constraints |
|--------|------|-------------|
| id | INTEGER | PRIMARY KEY |
| sensor_id | VARCHAR | NOT NULL, INDEX |
| sensor_type | VARCHAR | NOT NULL, INDEX |
| value | FLOAT | NOT NULL |
| timestamp | DATETIME | NOT NULL, INDEX, DEFAULT now() |

---

## ğŸ¤ Sunum SÄ±rasÄ±nda Vurgulanacak Noktalar

### 1. Asenkron YapÄ±
- "aiokafka kullanarak **async/await** pattern'i ile yÃ¼ksek performanslÄ± messaging"
- "FastAPI doÄŸal olarak async destekliyor"

### 2. Separation of Concerns
- "Producer API iÃ§inde, Consumer ayrÄ± process"
- "API Ã§Ã¶kse bile Consumer Ã§alÄ±ÅŸmaya devam eder"
- "Horizontal scaling: Consumer'larÄ± Ã§oÄŸaltabiliriz"

### 3. Error Handling
- "Kafka down olsa bile API Ã§alÄ±ÅŸÄ±r (try-catch)"
- "Consumer'da exception handling: Bir mesaj hatalÄ± olsa bile devam eder"

### 4. Data Flow
- "POST â†’ Kafka â†’ Consumer â†’ DB â†’ GET"
- "Decoupling: API ve DB arasÄ±nda Kafka buffer gÃ¶revi gÃ¶rÃ¼yor"
- "Message durability: Kafka'da mesajlar saklanÄ±yor"

### 5. Scalability
- "Consumer group ile multiple consumer"
- "Kafka partition'larÄ± artÄ±rarak throughput yÃ¼kseltebiliriz"
- "API stateless: Kubernetes'te scale edebiliriz"

---

## â“ OlasÄ± Sorular ve Cevaplar

### S: Neden Kafka kullandÄ±nÄ±z?

**C:** "Kafka, high-throughput ve fault-tolerant messaging saÄŸlÄ±yor. IoT senaryolarÄ±nda sensÃ¶rlerden gelen yÃ¼ksek hacimli veri akÄ±ÅŸÄ±nÄ± buffer'layarak DB'yi koruyabiliriz. AyrÄ±ca mesajlar Kafka'da saklandÄ±ÄŸÄ± iÃ§in data loss riski azalÄ±yor."

### S: Consumer neden ayrÄ± process?

**C:** "Separation of concerns. API sadece veri kabul edip Kafka'ya gÃ¶nderiyor. Consumer ise Kafka'dan okuyup DB iÅŸlemlerini yapÄ±yor. Bu sayede API fast response verebiliyor ve consumer baÄŸÄ±msÄ±z scale edilebiliyor."

### S: Duplicate kayÄ±tlar oluÅŸmuyor mu?

**C:** "Åu anda hem API hem Consumer DB'ye yazÄ±yor (demo iÃ§in). Production'da API sadece Kafka'ya gÃ¶nderir, ID yerine UUID kullanabiliriz. Ya da API response'unda ID dÃ¶ndÃ¼rmek yerine 'accepted' statÃ¼sÃ¼ dÃ¶nebiliriz."

### S: Kafka down olursa ne olur?

**C:** "API'de try-catch var, hata loglayÄ±p devam ediyor. Ä°stenirse fallback olarak direkt DB'ye yazabilir. Consumer tarafÄ±nda ise Kafka tekrar ayaÄŸa kalkÄ±nca kaldÄ±ÄŸÄ± yerden devam eder (offset commit sayesinde)."

### S: Birden fazla consumer Ã§alÄ±ÅŸabilir mi?

**C:** "Evet! AynÄ± consumer group ID'si ile birden fazla consumer baÅŸlatÄ±rsanÄ±z, Kafka mesajlarÄ± aralarÄ±nda daÄŸÄ±tÄ±r (load balancing). Her mesajÄ± sadece bir consumer iÅŸler."

### S: Message ordering garantisi var mÄ±?

**C:** "Kafka partition seviyesinde ordering garantisi verir. AynÄ± sensor_id'li mesajlar key olarak gÃ¶nderildiÄŸi iÃ§in aynÄ± partition'a dÃ¼ÅŸer, sÄ±ralÄ± iÅŸlenir."

---

## ğŸ“¸ Ekran GÃ¶rÃ¼ntÃ¼leri (Ä°steÄŸe BaÄŸlÄ±)

1. Swagger UI (POST endpoint)
2. Consumer terminal log'larÄ±
3. Kafka console consumer output
4. SQLite database iÃ§eriÄŸi
5. Test script baÅŸarÄ±lÄ± sonuÃ§

---

## ğŸ† SonuÃ§

**Tamamlanan:**
- âœ… Kafka Producer (async, JSON serialization)
- âœ… Kafka Consumer (async, ayrÄ± process, DB entegrasyonu)
- âœ… FastAPI startup/shutdown lifecycle integration
- âœ… Docker Compose ile Kafka kurulumu
- âœ… End-to-end data flow test

**Ã–ÄŸrenilen:**
- Event-driven architecture
- Message queue patterns
- Async Python (asyncio, aiokafka)
- Microservices communication
- Docker containerization

**Demo SÃ¼resi:** ~10 dakika

---

**HazÄ±r!** ğŸš€

