# IoT Sensor Data Collection Platform

This project is a simple IoT sensor data collection platform designed as a 3-layer architecture:

1. âœ… **API Layer (FastAPI + REST)** â€” TAMAMLANDI
2. âœ… **Messaging Layer (Kafka)** â€” TAMAMLANDI
3. âœ… **Data Layer (SQLAlchemy + Database)** â€” TAMAMLANDI

## ğŸ“Š Mimari

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   SensÃ¶r    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ HTTP POST
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      FastAPI (API Layer)    â”‚
â”‚  â€¢ POST /sensor/readings    â”‚
â”‚  â€¢ GET endpoints            â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€â”€â”€â–º Kafka Producer â”€â”€â–º [sensor.readings topic]
       â”‚                                    â”‚
       â””â”€â”€â”€â”€â”€â–º DB (geÃ§ici)                  â”‚
                                            â–¼
                                    Kafka Consumer
                                            â”‚
                                            â–¼
                                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                  â”‚  SQLite/Postgresâ”‚
                                  â”‚   (Data Layer)  â”‚
                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                            â”‚
                                            â–¼
                                    CRUD Operations
                                            â”‚
                                            â–¼
                                      GET Endpoints
```

---

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### Otomatik Kurulum (Ã–nerilen)

**Windows:**
```bash
# BaÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kle
pip install -r requirements.txt

# TÃ¼m servisleri baÅŸlat (Kafka + API + Consumer)
start_all.bat
```

**Linux/Mac:**
```bash
# BaÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kle
pip install -r requirements.txt

# TÃ¼m servisleri baÅŸlat
chmod +x start_all.sh
./start_all.sh
```

### Manuel Kurulum

#### 1. Clone the repository
```bash
git clone https://github.com/<your-username>/seng315-451-hw2-iot-platform.git  
cd seng315-451-hw2-iot-platform
```

#### 2. Create and activate virtual environment
**Windows:**
```bash
python -m venv venv  
venv\Scripts\activate.bat
```

**Linux/Mac:**
```bash
python -m venv venv
source venv/bin/activate
```

#### 3. Install dependencies
```bash
pip install -r requirements.txt
```

#### 4. Kafka'yÄ± baÅŸlat (Docker)
```bash
docker-compose up -d
```

#### 5. API'yi baÅŸlat (Terminal 1)
```bash
uvicorn app.main:app --reload --port 8000
```

#### 6. Consumer'Ä± baÅŸlat (Terminal 2)
```bash
python -m app.messaging.consumer_service
```

#### 7. Test et
```bash
python test_kafka.py
```

veya Swagger UI: http://localhost:8000/docs

---

## ğŸ”Œ API Endpoints

### 1. Health Check â€” GET /
Returns:
{ "message": "API layer is running" }

---

### 2. Create Sensor Reading â€” POST /sensor/readings
Request example:
{
  "sensor_id": "s1",
  "sensor_type": "temperature",
  "value": 23.5
}

Response:
{
  "id": 1,
  "sensor_id": "s1",
  "sensor_type": "temperature",
  "value": 23.5,
  "timestamp": "2025-11-28T13:50:12.123Z"
}

---

### 3. Get Latest Reading â€” GET /sensor/readings/latest/{sensor_id}

### 4. Get Sensor History â€” GET /sensor/readings/{sensor_id}?limit=50

### 5. Get Average By Sensor Type â€” GET /analytics/average?sensor_type=temperature
Example:
{
  "sensor_type": "temperature",
  "average": 23.8
}

---

## ğŸ“ Proje YapÄ±sÄ±

```
seng315-451-hw2-iot-platform/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                    # FastAPI app, endpoints
â”‚   â”œâ”€â”€ schemas.py                 # Pydantic models
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ db.py                  # SQLAlchemy setup & session
â”‚   â”‚   â”œâ”€â”€ models.py              # SensorReading model
â”‚   â”‚   â””â”€â”€ crud.py                # CRUD operations
â”‚   â””â”€â”€ messaging/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config.py              # Kafka config â­ KAFKA LAYER
â”‚       â”œâ”€â”€ producer.py            # Kafka producer â­ KAFKA LAYER
â”‚       â””â”€â”€ consumer_service.py    # Kafka consumer â­ KAFKA LAYER
â”œâ”€â”€ docker-compose.yml             # Kafka + Zookeeper
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ test_kafka.py                  # Integration test
â”œâ”€â”€ start_all.bat                  # Windows auto-start
â”œâ”€â”€ start_all.sh                   # Linux/Mac auto-start
â”œâ”€â”€ KAFKA_SETUP.md                 # DetaylÄ± Kafka kurulum kÄ±lavuzu
â””â”€â”€ README.md
```

## ğŸ§ª Test Etme

### 1. Otomatik Test Script'i
```bash
python test_kafka.py
```

### 2. Manuel Test (Swagger UI)
1. http://localhost:8000/docs adresine git
2. POST `/sensor/readings` ile veri gÃ¶nder:
```json
{
  "sensor_id": "temp_sensor_01",
  "sensor_type": "temperature",
  "value": 23.5
}
```
3. Consumer terminal'inde log'larÄ± izle
4. GET endpoint'leri ile verileri sorgula

### 3. Kafka'yÄ± DoÄŸrudan Test Et
```bash
# Kafka topic'ini kontrol et
docker exec -it kafka kafka-topics --bootstrap-server localhost:9092 --list

# MesajlarÄ± oku
docker exec -it kafka kafka-console-consumer --bootstrap-server localhost:9092 --topic sensor.readings --from-beginning
```

## ğŸ“š DetaylÄ± DokÃ¼mantasyon

Kafka entegrasyonu hakkÄ±nda detaylÄ± bilgi iÃ§in: **[KAFKA_SETUP.md](KAFKA_SETUP.md)**

## ğŸ¯ Tamamlanan Ã–zellikler

- âœ… FastAPI REST API
- âœ… Pydantic ÅŸema validasyonu
- âœ… SQLAlchemy ORM + SQLite database
- âœ… Kafka Producer (async)
- âœ… Kafka Consumer (async, ayrÄ± process)
- âœ… Docker Compose ile Kafka kurulumu
- âœ… CRUD operasyonlarÄ±
- âœ… Analytics endpoint (ortalama hesaplama)
- âœ… Otomatik baÅŸlatma script'leri
- âœ… Integration test script'i

## ğŸ”® Potansiyel Ä°yileÅŸtirmeler

- [ ] PostgreSQL desteÄŸi (ÅŸu an SQLite)
- [ ] Multiple partition support
- [ ] Error handling & retry logic
- [ ] Monitoring dashboard (Kafka UI, Prometheus)
- [ ] Authentication & authorization
- [ ] Rate limiting
- [ ] Daha fazla analytics (min/max, time-window stats)
- [ ] Kafka Streams ile real-time analytics
- [ ] Message validation & schema registry

## ğŸ‘¥ Ekip

- **API Layer:** TamamlandÄ±
- **Messaging Layer (Kafka):** TamamlandÄ± â­
- **Data Layer (SQLAlchemy):** Fatih (tamamlandÄ±)

## ğŸ“ Notlar

- Duplicate kayÄ±tlar: Åu an hem API hem Consumer DB'ye yazÄ±yor. Production'da sadece Kafka'ya gÃ¶nderip UUID kullanabilirsiniz.
- Error handling: Kafka down olsa bile API Ã§alÄ±ÅŸÄ±r.
- Consumer group: Scalability iÃ§in consumer'Ä± Ã§oÄŸaltabilirsiniz.

---

**Proje:** SENG315 / SENG451 Homework 2
**TarÄ±m:** AralÄ±k 2025
