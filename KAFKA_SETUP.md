# Kafka Messaging Layer - Kurulum ve Ã‡alÄ±ÅŸtÄ±rma KÄ±lavuzu

## ğŸ¯ Proje Mimarisi

```
SensÃ¶r â†’ POST API â†’ Kafka Producer â†’ sensor.readings topic
                                          â†“
                                   Kafka Consumer â†’ SQLite/PostgreSQL DB
                                          â†“
                            GET API â† DB â† CRUD Layer
```

## ğŸ“¦ Gereksinimler

- Python 3.8+
- Docker & Docker Compose (Kafka iÃ§in)
- pip

## ğŸš€ Kurulum AdÄ±mlarÄ±

### 1. Python BaÄŸÄ±mlÄ±lÄ±klarÄ±nÄ± YÃ¼kle

```bash
pip install -r requirements.txt
```

### 2. Kafka'yÄ± BaÅŸlat (Docker ile)

```bash
# Docker Compose ile Kafka ve Zookeeper'Ä± baÅŸlat
docker-compose up -d

# Kafka'nÄ±n hazÄ±r olduÄŸunu kontrol et
docker logs kafka
```

Kafka `localhost:9092` adresinde Ã§alÄ±ÅŸacak.

### 3. VeritabanÄ±nÄ± HazÄ±rla

VeritabanÄ± SQLite kullanÄ±yor ve otomatik oluÅŸturulacak. Ä°lk Ã§alÄ±ÅŸtÄ±rmada `sensor_db.sqlite3` dosyasÄ± oluÅŸturulur.

## ğŸ® Servisleri Ã‡alÄ±ÅŸtÄ±rma

### Terminal 1: FastAPI (API Layer)

```bash
uvicorn app.main:app --reload --port 8000
```

API: http://localhost:8000
Swagger UI: http://localhost:8000/docs

### Terminal 2: Kafka Consumer

```bash
python -m app.messaging.consumer_service
```

Consumer, Kafka'dan mesajlarÄ± okuyup veritabanÄ±na kaydeder.

## ğŸ§ª Test Senaryosu

### 1. Veri GÃ¶nder (POST)

Swagger UI'da veya curl ile:

```bash
curl -X POST "http://localhost:8000/sensor/readings" \
  -H "Content-Type: application/json" \
  -d '{
    "sensor_id": "temp_sensor_01",
    "sensor_type": "temperature",
    "value": 23.5
  }'
```

**Ne olur?**
- âœ… API veriyi alÄ±r
- âœ… Kafka'ya `sensor.readings` topic'ine gÃ¶nderir
- âœ… GeÃ§ici olarak DB'ye de yazar (hemen response dÃ¶nmek iÃ§in)
- âœ… Consumer Kafka'dan okuyup DB'ye kaydeder

### 2. Son Veriyi Oku (GET Latest)

```bash
curl "http://localhost:8000/sensor/readings/latest/temp_sensor_01"
```

### 3. GeÃ§miÅŸ Verileri Oku (GET History)

```bash
curl "http://localhost:8000/sensor/readings/temp_sensor_01?limit=10"
```

### 4. Ortalama Hesapla (Analytics)

```bash
curl "http://localhost:8000/analytics/average?sensor_type=temperature"
```

## ğŸ“Š Kafka Topic YÃ¶netimi

### Topic'leri Listele

```bash
docker exec -it kafka kafka-topics --bootstrap-server localhost:9092 --list
```

### Topic DetaylarÄ±nÄ± GÃ¶r

```bash
docker exec -it kafka kafka-topics --bootstrap-server localhost:9092 --describe --topic sensor.readings
```

### Topic'e Manuel Mesaj GÃ¶nder (Test iÃ§in)

```bash
docker exec -it kafka kafka-console-producer --bootstrap-server localhost:9092 --topic sensor.readings
```

### Topic'ten Mesaj Oku (Test iÃ§in)

```bash
docker exec -it kafka kafka-console-consumer --bootstrap-server localhost:9092 --topic sensor.readings --from-beginning
```

## ğŸ—ï¸ Dosya YapÄ±sÄ±

```
app/
â”œâ”€â”€ main.py                      # FastAPI app, endpoints
â”œâ”€â”€ schemas.py                   # Pydantic models
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ db.py                    # SQLAlchemy setup
â”‚   â”œâ”€â”€ models.py                # DB models
â”‚   â””â”€â”€ crud.py                  # DB operations
â””â”€â”€ messaging/
    â”œâ”€â”€ config.py                # Kafka config (SENIN Ä°ÅÄ°N)
    â”œâ”€â”€ producer.py              # Kafka producer (SENIN Ä°ÅÄ°N)
    â””â”€â”€ consumer_service.py      # Kafka consumer (SENIN Ä°ÅÄ°N)
```

## ğŸ“ Hocaya GÃ¶sterim Senaryosu

1. **Kafka'yÄ± baÅŸlat:**
   ```bash
   docker-compose up -d
   ```

2. **API'yi baÅŸlat (Terminal 1):**
   ```bash
   uvicorn app.main:app --reload
   ```

3. **Consumer'Ä± baÅŸlat (Terminal 2):**
   ```bash
   python -m app.messaging.consumer_service
   ```

4. **Swagger UI'da test et:**
   - http://localhost:8000/docs
   - POST `/sensor/readings` ile 3-4 farklÄ± sensÃ¶r verisi gÃ¶nder
   - Consumer terminal'de loglarÄ± gÃ¶ster (mesajlar DB'ye kaydediliyor)
   - GET endpoint'leri ile verileri gÃ¶ster

5. **Kafka'yÄ± gÃ¶ster:**
   ```bash
   docker exec -it kafka kafka-console-consumer --bootstrap-server localhost:9092 --topic sensor.readings --from-beginning
   ```

## ğŸ”§ KonfigÃ¼rasyon

### Kafka AyarlarÄ± (app/messaging/config.py)

```python
KAFKA_BOOTSTRAP_SERVERS = "localhost:9092"
SENSOR_TOPIC = "sensor.readings"
CONSUMER_GROUP_ID = "sensor-consumer-group"
```

### VeritabanÄ± (app/database/db.py)

```python
SQLALCHEMY_DATABASE_URL = "sqlite:///./sensor_db.sqlite3"
```

PostgreSQL iÃ§in deÄŸiÅŸtir:
```python
SQLALCHEMY_DATABASE_URL = "postgresql://user:password@localhost/sensor_db"
```

## ğŸ› Sorun Giderme

### Kafka baÄŸlanamÄ±yor

```bash
# Kafka container'Ä±nÄ± kontrol et
docker ps
docker logs kafka

# Kafka'yÄ± yeniden baÅŸlat
docker-compose restart kafka
```

### Consumer Ã§alÄ±ÅŸmÄ±yor

```bash
# Topic'in oluÅŸtuÄŸunu kontrol et
docker exec -it kafka kafka-topics --bootstrap-server localhost:9092 --list

# Consumer log seviyesini artÄ±r
# consumer_service.py'de logging.INFO -> logging.DEBUG
```

### DB hatasÄ±

```bash
# DB dosyasÄ±nÄ± sil ve yeniden oluÅŸtur
rm sensor_db.sqlite3
# API'yi tekrar baÅŸlat (otomatik oluÅŸturur)
```

## ğŸ“ Notlar

- **Duplicate kayÄ±tlar:** Åu an hem API hem Consumer DB'ye yazÄ±yor (response iÃ§in gerekli). Production'da sadece Kafka'ya gÃ¶nderip UUID kullanabilirsiniz.
- **Error handling:** Kafka down olsa bile API Ã§alÄ±ÅŸÄ±r (try-catch var).
- **Scalability:** Consumer'Ä± Ã§oÄŸaltabilirsiniz (consumer group sayesinde).
- **Monitoring:** Production'da Kafka monitoring araÃ§larÄ± kullanÄ±n (Kafka UI, Prometheus, vb.).

## ğŸ‰ BaÅŸarÄ± Kriterleri

âœ… POST endpoint Kafka'ya veri gÃ¶nderiyor
âœ… Consumer Kafka'dan veri okuyup DB'ye yazÄ±yor
âœ… GET endpoint'leri DB'den veri okuyor
âœ… Analytics endpoint Ã§alÄ±ÅŸÄ±yor
âœ… Docker ile Kafka Ã§alÄ±ÅŸÄ±yor

---

**HazÄ±rlayan:** Messaging Layer Ekibi
**Tarih:** AralÄ±k 2025
**Proje:** SENG315-451 HW2 - IoT Platform

